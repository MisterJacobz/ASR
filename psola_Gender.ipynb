{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.fft import fft, ifft\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import speech_recognition\n",
    "import soundfile as sf\n",
    "from io import BytesIO\n",
    "import jiwer\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import soundfile\n",
    "import wave\n",
    "from IPython.display import Audio, Markdown\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Psola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemetation from https://github.com/sannawag/TD-PSOLA/blob/master/td_psola.py\n",
    "def psola(signal, peaks, f_ratio):\n",
    "    \"\"\"\n",
    "    Time-Domain Pitch Synchronous Overlap and Add\n",
    "    :param signal: original time-domain signal\n",
    "    :param peaks: time-domain signal peak indices\n",
    "    :param f_ratio: pitch shift ratio\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    # Interpolate\n",
    "    new_signal = np.zeros(N)\n",
    "    new_peaks_ref = np.linspace(0, len(peaks) - 1, int(len(peaks) * f_ratio))\n",
    "    new_peaks = np.zeros(len(new_peaks_ref)).astype(int)\n",
    "    \n",
    "    for i in range(len(new_peaks)):\n",
    "        weight = new_peaks_ref[i] % 1\n",
    "        left = np.floor(new_peaks_ref[i]).astype(int)\n",
    "        right = np.ceil(new_peaks_ref[i]).astype(int)\n",
    "        new_peaks[i] = int(peaks[left] * (1 - weight) + peaks[right] * weight)\n",
    "\n",
    "    # PSOLA\n",
    "    for j in range(len(new_peaks)):\n",
    "        # find the corresponding old peak index\n",
    "        i = np.argmin(np.abs(peaks - new_peaks[j]))\n",
    "        # get the distances to adjacent peaks\n",
    "        P1 = [new_peaks[j] if j == 0 else new_peaks[j] - new_peaks[j-1],\n",
    "              N - 1 - new_peaks[j] if j == len(new_peaks) - 1 else new_peaks[j+1] - new_peaks[j]]\n",
    "        # edge case truncation\n",
    "        if peaks[i] - P1[0] < 0:\n",
    "            P1[0] = peaks[i]\n",
    "        if peaks[i] + P1[1] > N - 1:\n",
    "            P1[1] = N - 1 - peaks[i]\n",
    "        # linear OLA window\n",
    "        window = list(np.linspace(0, 1, P1[0] + 1)[1:]) + list(np.linspace(1, 0, P1[1] + 1)[1:])\n",
    "        # center window from original signal at the new peak\n",
    "        new_signal[new_peaks[j] - P1[0]: new_peaks[j] + P1[1]] += window * signal[peaks[i] - P1[0]: peaks[i] + P1[1]]\n",
    "    return new_signal\n",
    "\n",
    "def compute_periods_per_sequence(signal, sequence, min_period, max_period):\n",
    "    \"\"\"\n",
    "    Computes periodicity of a time-domain signal using autocorrelation\n",
    "    :param sequence: analysis window length in samples. Computes one periodicity value per window\n",
    "    :param min_period: smallest allowed periodicity\n",
    "    :param max_period: largest allowed periodicity\n",
    "    :return: list of measured periods in windows across the signal\n",
    "    \"\"\"\n",
    "    offset = 0  # current sample offset\n",
    "    periods = []  # period length of each analysis sequence\n",
    "    N = len(signal)\n",
    "    while offset < N:\n",
    "        fourier = fft(signal[offset: offset + sequence])\n",
    "        fourier[0] = 0  # remove DC component\n",
    "        autoc = ifft(fourier * np.conj(fourier)).real\n",
    "        if len(autoc) <= min_period:\n",
    "            autoc_peak = min_period + autoc[-1]\n",
    "        else:    \n",
    "            autoc_peak = min_period + np.argmax(autoc[min_period: max_period])\n",
    "        periods.append(autoc_peak)\n",
    "        offset += sequence\n",
    "    return periods\n",
    "\n",
    "def find_peaks(signal, fs, max_hz=950, min_hz=75, analysis_win_ms=40, max_change=1.005, min_change=0.995):\n",
    "    \"\"\"\n",
    "    Find sample indices of peaks in time-domain signal\n",
    "    :param max_hz: maximum measured fundamental frequency\n",
    "    :param min_hz: minimum measured fundamental frequency\n",
    "    :param analysis_win_ms: window size used for autocorrelation analysis\n",
    "    :param max_change: restrict periodicity to not increase by more than this ratio from the mean\n",
    "    :param min_change: restrict periodicity to not decrease by more than this ratio from the mean\n",
    "    :return: peak indices\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    min_period = fs // max_hz\n",
    "    max_period = fs // min_hz\n",
    "\n",
    "    # compute pitch periodicity\n",
    "    sequence = int(analysis_win_ms / 1000 * fs)  # analysis sequence length in samples\n",
    "\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period)\n",
    "\n",
    "    # simple hack to avoid octave error: assume that the pitch should not vary much, restrict range\n",
    "    mean_period = np.mean(periods)\n",
    "    max_period = int(mean_period * 1.1)\n",
    "    min_period = int(mean_period * 0.9)\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period)\n",
    "\n",
    "    # find the peaks\n",
    "    peaks = [np.argmax(signal[:int(periods[0]*1.1)])]\n",
    "    while True:\n",
    "        prev = peaks[-1]\n",
    "        idx = prev // sequence  # current autocorrelation analysis window\n",
    "        if prev + int(periods[idx] * max_change) >= N:\n",
    "            break\n",
    "        # find maximum near expected location\n",
    "        peaks.append(prev + int(periods[idx] * min_change) +\n",
    "                np.argmax(signal[prev + int(periods[idx] * min_change): prev + int(periods[idx] * max_change)]))\n",
    "    return np.array(peaks)\n",
    "\n",
    "def shift_pitch(signal, fs, f_ratio):\n",
    "    \"\"\"\n",
    "    Calls psola pitch shifting algorithm\n",
    "    :param signal: original signal in the time-domain\n",
    "    :param fs: sample rate\n",
    "    :param f_ratio: ratio by which the frequency will be shifted\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    peaks = find_peaks(signal, fs)\n",
    "    new_signal = psola(signal, peaks, f_ratio)\n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(input_signal, noise_level):\n",
    "    white_noise = np.random.randn(len(input_signal))\n",
    "    mixed_audio = input_signal + noise_level * white_noise[:len(input_signal)]\n",
    "    return mixed_audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file, recognizer, language):\n",
    "    # Language Code for Dutch = \"nl-NL\", for english use \"en-US\"\n",
    "    \n",
    "    # try:\n",
    "    wav_io = BytesIO()\n",
    "    sf.write(wav_io, file, 16000, format='WAV')\n",
    "    wav_io.seek(0)\n",
    "    \n",
    "    audio_file = speech_recognition.AudioFile(wav_io)\n",
    "    with audio_file as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "    \n",
    "    text = recognizer.recognize_whisper(audio_data, language)\n",
    "    wav_io.close()\n",
    "    if text == \"\":\n",
    "        text = \"empty\"\n",
    "    return text  \n",
    "    # except:\n",
    "    #     return \"empty\"\n",
    "    # finally:\n",
    "    #    wav_io.close()\n",
    "      \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(y, n_mfcc=13, rate=16000):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the audio file.\n",
    "    n_mfcc (int): Number of MFCC features to extract.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Extracted MFCC features.\n",
    "    \"\"\"\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=rate, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs.T, axis=0)  # Average across time frames\n",
    "\n",
    "def aggregate_speaker_features(files):\n",
    "    \"\"\"\n",
    "    Aggregate MFCC features for all recordings of a speaker.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths for a single speaker's recordings.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Aggregated feature vector for the speaker.\n",
    "    \"\"\"\n",
    "    features = [extract_mfcc(file) for file in files]\n",
    "    return np.mean(features, axis=0)\n",
    "\n",
    "def get_speaker_files(base_path):\n",
    "    \"\"\"\n",
    "    Get a dictionary of speaker IDs and their corresponding file paths.\n",
    "    \n",
    "    Parameters:\n",
    "    base_path (str): Base directory containing the audio files.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with speaker IDs as keys and lists of file paths as values.\n",
    "    \"\"\"\n",
    "    speaker_files = defaultdict(list)\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.endswith('.wav'):\n",
    "            speaker_id = file.split('-')[0]\n",
    "            speaker_files[speaker_id].append(os.path.join(base_path, file))\n",
    "    return speaker_files\n",
    "\n",
    "def calculate_similarity_matrix(utterances):\n",
    "    \"\"\"\n",
    "    Compute the voice similarity matrix for given utterances.\n",
    "    \n",
    "    Parameters:\n",
    "    utterances (list): List of feature vectors representing each speaker.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Similarity matrix.\n",
    "    \"\"\"\n",
    "    num_speakers = len(utterances)\n",
    "    similarity_matrix = np.zeros((num_speakers, num_speakers))\n",
    "    \n",
    "    for i in range(num_speakers):\n",
    "        for j in range(num_speakers):\n",
    "            similarity_matrix[i, j] = np.dot(utterances[i], utterances[j]) / (np.linalg.norm(utterances[i]) * np.linalg.norm(utterances[j]))\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "def calculate_diagonal_dominance(matrix):\n",
    "    \"\"\"\n",
    "    Calculate the diagonal dominance of a given similarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.ndarray): Similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: Diagonal dominance value.\n",
    "    \"\"\"\n",
    "    N = matrix.shape[0]\n",
    "    diag_avg = np.mean(np.diag(matrix))\n",
    "    off_diag_mask = np.ones(matrix.shape, dtype=bool)\n",
    "    np.fill_diagonal(off_diag_mask, 0)\n",
    "    off_diag_avg = np.mean(matrix[off_diag_mask])\n",
    "    \n",
    "    return abs(diag_avg - off_diag_avg)\n",
    "\n",
    "def calculate_deid(matrix_oo, matrix_op):\n",
    "    \"\"\"\n",
    "    Calculate the DeID metric given the original and original-protected similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix_oo (np.ndarray): Original similarity matrix.\n",
    "    matrix_op (np.ndarray): Original-protected similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: DeID metric.\n",
    "    \"\"\"\n",
    "    D_diag_OO = calculate_diagonal_dominance(matrix_oo)\n",
    "    D_diag_OP = calculate_diagonal_dominance(matrix_op)\n",
    "    \n",
    "    DeID = 1 - (D_diag_OP / D_diag_OO)\n",
    "    return DeID\n",
    "\n",
    "def calculate_gvd(matrix_oo, matrix_pp):\n",
    "    \"\"\"\n",
    "    Calculate the GVD metric given the original and pseudonymised similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix_oo (np.ndarray): Original similarity matrix.\n",
    "    matrix_pp (np.ndarray): Pseudonymised similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: GVD metric.\n",
    "    \"\"\"\n",
    "    D_diag_OO = calculate_diagonal_dominance(matrix_oo)\n",
    "    D_diag_PP = calculate_diagonal_dominance(matrix_pp)\n",
    "    \n",
    "    GVD = 10 * np.log10(D_diag_PP / D_diag_OO)\n",
    "    return GVD\n",
    "\n",
    "# Gender mapping\n",
    "spk2gender = {\n",
    "    '1272': 'm', '1462': 'f', '1673': 'f', '174': 'm', '1919': 'f', '1988': 'f', \n",
    "    '1993': 'f', '2035': 'f', '2078': 'm', '2086': 'm', '2277': 'f', '2412': 'f', \n",
    "    '2428': 'm', '251': 'm', '2803': 'm', '2902': 'm', '3000': 'm', '3081': 'f', \n",
    "    '3170': 'm', '3536': 'f', '3576': 'f', '3752': 'm', '3853': 'f', '422': 'm', \n",
    "    '5338': 'f', '5536': 'm', '5694': 'm', '5895': 'f', '6241': 'm', '6295': 'm', \n",
    "    '6313': 'f', '6319': 'f', '6345': 'f', '652': 'm', '777': 'm', '7850': 'f', \n",
    "    '7976': 'm', '8297': 'm', '84': 'f', '8842': 'f'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On dev-clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/dev-clean-audio'\n",
    "audio_dict = {}\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        if file.endswith('.wav'):\n",
    "            temp_dict = {}\n",
    "            original, rate = librosa.load(file_path, sr=16000)\n",
    "            temp_dict['original'] = original\n",
    "            f_ratio = 1.3\n",
    "            psola_audio = shift_pitch(original, rate, f_ratio)\n",
    "            temp_dict['psola'] = psola_audio\n",
    "            noise_audio = add_noise(psola_audio, 0.001)\n",
    "            temp_dict['noise'] = noise_audio\n",
    "            key = file.split('.')[0]\n",
    "            audio_dict[key] = temp_dict\n",
    "        # elif file.endswith('.txt'):\n",
    "        #     with open(file_path, 'r') as f:\n",
    "        #         for line in f:\n",
    "        #             key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "        #             key = key.strip()\n",
    "        #             sentence = sentence.strip()\n",
    "        #             audio_dict[key]['transcript'] = sentence\n",
    "\n",
    "trancript_filepath = \"data/dev-clean-audio/transcript.txt\"\n",
    "with open(trancript_filepath, 'r') as f:\n",
    "    for line in f:\n",
    "        key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "        key = key.strip()\n",
    "        sentence = sentence.strip()\n",
    "        audio_dict[key]['transcript'] = sentence\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeID & GVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male DeID: 0.11, Male GVD: -0.88\n",
      "Female DeID: 0.12, Female GVD: -0.86\n",
      "Male DeID: 0.20, Male GVD: -1.43\n",
      "Female DeID: 0.16, Female GVD: -0.95\n"
     ]
    }
   ],
   "source": [
    "speaker_files = defaultdict(list)\n",
    "speaker_files_psola = defaultdict(list)\n",
    "speaker_files_noise = defaultdict(list)\n",
    "for key, items in audio_dict.items():\n",
    "   speaker_id = key.split('-')[0] \n",
    "   speaker_files[speaker_id].append(items['original'])\n",
    "   speaker_files_psola[speaker_id].append(items['psola'])\n",
    "   speaker_files_noise[speaker_id].append(items['noise'])\n",
    "\n",
    "# Separating male and female speakers\n",
    "male_speakers = {spk: paths for spk, paths in speaker_files.items() if spk2gender[spk] == 'm'}\n",
    "female_speakers = {spk: paths for spk, paths in speaker_files.items() if spk2gender[spk] == 'f'}\n",
    "psola_male_speakers = {spk: paths for spk, paths in speaker_files_psola.items() if spk2gender[spk] == 'm'}\n",
    "psola_female_speakers = {spk: paths for spk, paths in speaker_files_psola.items() if spk2gender[spk] == 'f'}\n",
    "noise_male_speakers = {spk: paths for spk, paths in speaker_files_noise.items() if spk2gender[spk] == 'm'}\n",
    "noise_female_speakers = {spk: paths for spk, paths in speaker_files_noise.items() if spk2gender[spk] == 'f'}\n",
    "\n",
    "utterances_male = [aggregate_speaker_features(paths) for spk, paths in male_speakers.items()]\n",
    "utterances_female = [aggregate_speaker_features(paths) for spk, paths in female_speakers.items()]\n",
    "utterances_psola_male = [aggregate_speaker_features(paths) for spk, paths in psola_male_speakers.items()]\n",
    "utterances_psola_female = [aggregate_speaker_features(paths) for spk, paths in psola_female_speakers.items()]\n",
    "utterances_noise_male = [aggregate_speaker_features(paths) for spk, paths in noise_male_speakers.items()]\n",
    "utterances_noise_female = [aggregate_speaker_features(paths) for spk, paths in noise_female_speakers.items()]\n",
    "\n",
    "# Calculating similarity matrices for male and female\n",
    "matrix_oo_male = calculate_similarity_matrix(utterances_male)\n",
    "matrix_oo_female = calculate_similarity_matrix(utterances_female)\n",
    "\n",
    "# Psola\n",
    "# Male DeID and GVD\n",
    "matrix_op_male_psola = calculate_similarity_matrix(utterances_male + utterances_psola_male)[len(utterances_male):, :len(utterances_male)]\n",
    "matrix_pp_male_psola = calculate_similarity_matrix(utterances_psola_male)\n",
    "\n",
    "deid_male_psola = calculate_deid(matrix_oo_male, matrix_op_male_psola)\n",
    "gvd_male_psola = calculate_gvd(matrix_oo_male, matrix_pp_male_psola)\n",
    "\n",
    "# Female DeID and GVD\n",
    "matrix_op_female_psola = calculate_similarity_matrix(utterances_female + utterances_psola_female)[len(utterances_female):, :len(utterances_female)]\n",
    "matrix_pp_female_psola = calculate_similarity_matrix(utterances_psola_female)\n",
    "\n",
    "deid_female_psola = calculate_deid(matrix_oo_female, matrix_op_female_psola)\n",
    "gvd_female_psola = calculate_gvd(matrix_oo_female, matrix_pp_female_psola)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Male DeID: {deid_male_psola:.2f}, Male GVD: {gvd_male_psola:.2f}\")\n",
    "print(f\"Female DeID: {deid_female_psola:.2f}, Female GVD: {gvd_female_psola:.2f}\")\n",
    "\n",
    "# Psola + Noise\n",
    "# Male DeID and GVD\n",
    "matrix_op_male_noise = calculate_similarity_matrix(utterances_male + utterances_noise_male)[len(utterances_male):, :len(utterances_male)]\n",
    "matrix_pp_male_noise = calculate_similarity_matrix(utterances_noise_male)\n",
    "\n",
    "deid_male_noise = calculate_deid(matrix_oo_male, matrix_op_male_noise)\n",
    "gvd_male_noise = calculate_gvd(matrix_oo_male, matrix_pp_male_noise)\n",
    "\n",
    "# Female DeID and GVD\n",
    "matrix_op_female_noise = calculate_similarity_matrix(utterances_female + utterances_noise_female)[len(utterances_female):, :len(utterances_female)]\n",
    "matrix_pp_female_noise = calculate_similarity_matrix(utterances_noise_female)\n",
    "\n",
    "deid_female_noise = calculate_deid(matrix_oo_female, matrix_op_female_noise)\n",
    "gvd_female_noise = calculate_gvd(matrix_oo_female, matrix_pp_female_noise)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Male DeID: {deid_male_noise:.2f}, Male GVD: {gvd_male_noise:.2f}\")\n",
    "print(f\"Female DeID: {deid_female_noise:.2f}, Female GVD: {gvd_female_noise:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store WER values for male and female speakers\n",
    "clean_wer_male = []\n",
    "clean_wer_female = []\n",
    "psola_wer_male = []\n",
    "psola_wer_female = []\n",
    "noise_wer_male = []\n",
    "noise_wer_female = []\n",
    "\n",
    "recognizer = speech_recognition.Recognizer()\n",
    "\n",
    "for key in audio_dict.keys():\n",
    "    transcript = audio_dict[key]['transcript'].lower()\n",
    "    speaker_id = key.split('-')[0]\n",
    "    gender = spk2gender[speaker_id]\n",
    "    \n",
    "    # clean\n",
    "    text = transcribe_audio(audio_dict[key]['original'], recognizer, 'tiny')\n",
    "    if text != \"empty\":\n",
    "        if gender == 'm':\n",
    "            clean_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "        else:\n",
    "            clean_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # psola\n",
    "    text = transcribe_audio(audio_dict[key]['psola'], recognizer, 'tiny')\n",
    "    if text != \"empty\":\n",
    "        if gender == 'm':\n",
    "            psola_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "        else:\n",
    "            psola_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # noise\n",
    "    text = transcribe_audio(audio_dict[key]['noise'], recognizer, 'tiny')\n",
    "    if text != \"empty\":\n",
    "        if gender == 'm':\n",
    "            noise_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "        else:\n",
    "            noise_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "\n",
    "# Calculate average WER for male and female speakers\n",
    "clean_wer_male_avg = sum(clean_wer_male) / len(clean_wer_male) if clean_wer_male else float('nan')\n",
    "clean_wer_female_avg = sum(clean_wer_female) / len(clean_wer_female) if clean_wer_female else float('nan')\n",
    "\n",
    "psola_wer_male_avg = sum(psola_wer_male) / len(psola_wer_male) if psola_wer_male else float('nan')\n",
    "psola_wer_female_avg = sum(psola_wer_female) / len(psola_wer_female) if psola_wer_female else float('nan')\n",
    "\n",
    "noise_wer_male_avg = sum(noise_wer_male) / len(noise_wer_male) if noise_wer_male else float('nan')\n",
    "noise_wer_female_avg = sum(noise_wer_female) / len(noise_wer_female) if noise_wer_female else float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before WER Male: 0.24064532517504428\n",
      "Before WER Female: 0.2269092437386394\n",
      "PSOLA WER Male: 0.2540091962794962\n",
      "PSOLA WER Female: 0.245975442593483\n",
      "PSOLA + noise WER Male: 0.26078805544122147\n",
      "PSOLA + noise WER Female: 0.2507533470189283\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(f\"Before WER Male: {clean_wer_male_avg}\")\n",
    "print(f\"Before WER Female: {clean_wer_female_avg}\")\n",
    "print(f\"PSOLA WER Male: {psola_wer_male_avg}\")\n",
    "print(f\"PSOLA WER Female: {psola_wer_female_avg}\")\n",
    "print(f\"PSOLA + noise WER Male: {noise_wer_male_avg}\")\n",
    "print(f\"PSOLA + noise WER Female: {noise_wer_female_avg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
