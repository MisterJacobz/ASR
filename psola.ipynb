{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.fft import fft, ifft\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "import speech_recognition as sr\n",
    "import soundfile as sf\n",
    "from io import BytesIO\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Psola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemetation from https://github.com/sannawag/TD-PSOLA/blob/master/td_psola.py\n",
    "def psola(signal, peaks, f_ratio):\n",
    "    \"\"\"\n",
    "    Time-Domain Pitch Synchronous Overlap and Add\n",
    "    :param signal: original time-domain signal\n",
    "    :param peaks: time-domain signal peak indices\n",
    "    :param f_ratio: pitch shift ratio\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    # Interpolate\n",
    "    new_signal = np.zeros(N)\n",
    "    new_peaks_ref = np.linspace(0, len(peaks) - 1, int(len(peaks) * f_ratio))\n",
    "    new_peaks = np.zeros(len(new_peaks_ref)).astype(int)\n",
    "    \n",
    "    for i in range(len(new_peaks)):\n",
    "        weight = new_peaks_ref[i] % 1\n",
    "        left = np.floor(new_peaks_ref[i]).astype(int)\n",
    "        right = np.ceil(new_peaks_ref[i]).astype(int)\n",
    "        new_peaks[i] = int(peaks[left] * (1 - weight) + peaks[right] * weight)\n",
    "\n",
    "    # PSOLA\n",
    "    for j in range(len(new_peaks)):\n",
    "        # find the corresponding old peak index\n",
    "        i = np.argmin(np.abs(peaks - new_peaks[j]))\n",
    "        # get the distances to adjacent peaks\n",
    "        P1 = [new_peaks[j] if j == 0 else new_peaks[j] - new_peaks[j-1],\n",
    "              N - 1 - new_peaks[j] if j == len(new_peaks) - 1 else new_peaks[j+1] - new_peaks[j]]\n",
    "        # edge case truncation\n",
    "        if peaks[i] - P1[0] < 0:\n",
    "            P1[0] = peaks[i]\n",
    "        if peaks[i] + P1[1] > N - 1:\n",
    "            P1[1] = N - 1 - peaks[i]\n",
    "        # linear OLA window\n",
    "        window = list(np.linspace(0, 1, P1[0] + 1)[1:]) + list(np.linspace(1, 0, P1[1] + 1)[1:])\n",
    "        # center window from original signal at the new peak\n",
    "        new_signal[new_peaks[j] - P1[0]: new_peaks[j] + P1[1]] += window * signal[peaks[i] - P1[0]: peaks[i] + P1[1]]\n",
    "    return new_signal\n",
    "\n",
    "def compute_periods_per_sequence(signal, sequence, min_period, max_period):\n",
    "    \"\"\"\n",
    "    Computes periodicity of a time-domain signal using autocorrelation\n",
    "    :param sequence: analysis window length in samples. Computes one periodicity value per window\n",
    "    :param min_period: smallest allowed periodicity\n",
    "    :param max_period: largest allowed periodicity\n",
    "    :return: list of measured periods in windows across the signal\n",
    "    \"\"\"\n",
    "    offset = 0  # current sample offset\n",
    "    periods = []  # period length of each analysis sequence\n",
    "    N = len(signal)\n",
    "    while offset < N:\n",
    "        fourier = fft(signal[offset: offset + sequence])\n",
    "        fourier[0] = 0  # remove DC component\n",
    "        autoc = ifft(fourier * np.conj(fourier)).real\n",
    "        if len(autoc) <= min_period:\n",
    "            autoc_peak = min_period + autoc[-1]\n",
    "        else:    \n",
    "            autoc_peak = min_period + np.argmax(autoc[min_period: max_period])\n",
    "        periods.append(autoc_peak)\n",
    "        offset += sequence\n",
    "    return periods\n",
    "\n",
    "def find_peaks(signal, fs, max_hz=950, min_hz=75, analysis_win_ms=40, max_change=1.005, min_change=0.995):\n",
    "    \"\"\"\n",
    "    Find sample indices of peaks in time-domain signal\n",
    "    :param max_hz: maximum measured fundamental frequency\n",
    "    :param min_hz: minimum measured fundamental frequency\n",
    "    :param analysis_win_ms: window size used for autocorrelation analysis\n",
    "    :param max_change: restrict periodicity to not increase by more than this ratio from the mean\n",
    "    :param min_change: restrict periodicity to not decrease by more than this ratio from the mean\n",
    "    :return: peak indices\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    min_period = fs // max_hz\n",
    "    max_period = fs // min_hz\n",
    "\n",
    "    # compute pitch periodicity\n",
    "    sequence = int(analysis_win_ms / 1000 * fs)  # analysis sequence length in samples\n",
    "\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period)\n",
    "\n",
    "    # simple hack to avoid octave error: assume that the pitch should not vary much, restrict range\n",
    "    mean_period = np.mean(periods)\n",
    "    max_period = int(mean_period * 1.1)\n",
    "    min_period = int(mean_period * 0.9)\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period)\n",
    "\n",
    "    # find the peaks\n",
    "    peaks = [np.argmax(signal[:int(periods[0]*1.1)])]\n",
    "    while True:\n",
    "        prev = peaks[-1]\n",
    "        idx = prev // sequence  # current autocorrelation analysis window\n",
    "        if prev + int(periods[idx] * max_change) >= N:\n",
    "            break\n",
    "        # find maximum near expected location\n",
    "        peaks.append(prev + int(periods[idx] * min_change) +\n",
    "                np.argmax(signal[prev + int(periods[idx] * min_change): prev + int(periods[idx] * max_change)]))\n",
    "    return np.array(peaks)\n",
    "\n",
    "def shift_pitch(signal, fs, f_ratio):\n",
    "    \"\"\"\n",
    "    Calls psola pitch shifting algorithm\n",
    "    :param signal: original signal in the time-domain\n",
    "    :param fs: sample rate\n",
    "    :param f_ratio: ratio by which the frequency will be shifted\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    peaks = find_peaks(signal, fs)\n",
    "    new_signal = psola(signal, peaks, f_ratio)\n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(input_signal, noise_level):\n",
    "    white_noise = np.random.randn(len(input_signal))\n",
    "    mixed_audio = input_signal + noise_level * white_noise[:len(input_signal)]\n",
    "    return mixed_audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file, recognizer, language):\n",
    "    # Language Code for Dutch = \"nl-NL\", for english use \"en-US\"\n",
    "    \n",
    "    # try:\n",
    "    wav_io = BytesIO()\n",
    "    sf.write(wav_io, file, 16000, format='WAV')\n",
    "    wav_io.seek(0)\n",
    "    \n",
    "    audio_file = sr.AudioFile(wav_io)\n",
    "    with audio_file as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "    \n",
    "    text = recognizer.recognize_whisper(audio_data, language)\n",
    "    wav_io.close()\n",
    "    return text  \n",
    "    # except:\n",
    "    #     return \"empty\"\n",
    "    # finally:\n",
    "    #    wav_io.close()\n",
    "      \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On dev-clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/dev-clean-audio'\n",
    "audio_dict = {}\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        if file.endswith('.flac'):\n",
    "            temp_dict = {}\n",
    "            original, rate = librosa.load(file_path, sr=16000)\n",
    "            temp_dict['original'] = original\n",
    "            f_ratio = 1.3\n",
    "            psola_audio = shift_pitch(original, rate, f_ratio)\n",
    "            temp_dict['psola'] = psola_audio\n",
    "            noise_audio = add_noise(psola_audio, 0.001)\n",
    "            temp_dict['noise'] = noise_audio\n",
    "            key = file.split('.')[0]\n",
    "            audio_dict[key] = temp_dict\n",
    "        elif file.endswith('.txt'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "                    key = key.strip()\n",
    "                    sentence = sentence.strip()\n",
    "                    audio_dict[key]['transcript'] = sentence\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = audio_dict['1272-128104-0013']['original']\n",
    "psola = audio_dict['1272-128104-0013']['psola']\n",
    "noise = audio_dict['1272-128104-0013']['noise']\n",
    "ipd.display(ipd.HTML('Original'))\n",
    "ipd.display(ipd.Audio(original, rate=rate))\n",
    "\n",
    "ipd.display(ipd.HTML('Anonymized'))\n",
    "ipd.display(ipd.Audio(psola, rate=rate))\n",
    "\n",
    "ipd.display(ipd.HTML('with noise'))\n",
    "ipd.display(ipd.Audio(noise, rate=rate))\n",
    "\n",
    "\n",
    "print(audio_dict['1272-128104-0013']['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wer = []\n",
    "psola_wer = []\n",
    "noise_wer = []\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "\n",
    "for key in audio_dict.keys():\n",
    "    transcript = audio_dict[key]['transcript'].lower()\n",
    "    \n",
    "    # clean\n",
    "    text = transcribe_audio(audio_dict[key]['psola'], recognizer, 'small')\n",
    "    clean_wer.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # psola\n",
    "    text = transcribe_audio(audio_dict[key]['psola'], recognizer, 'small')\n",
    "    psola_wer.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # noise\n",
    "    text = transcribe_audio(audio_dict[key]['noise'], recognizer, 'small')\n",
    "    noise_wer.append(jiwer.wer(text.lower(), transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: \", sum(clean_wer) / len(clean_wer))\n",
    "print(\"PSOLA: \", sum(psola_wer) / len(psola_wer))\n",
    "print(\"PSOLA + noise: \", sum(noise_wer) / len(noise_wer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On dutch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/nl'\n",
    "audio_dict_NL = {}\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        if file.endswith('.wav'):\n",
    "            temp_dict = {}\n",
    "            original, rate = librosa.load(file_path, sr=16000)\n",
    "            temp_dict['original'] = original\n",
    "            f_ratio = 1.3\n",
    "            psola_audio = shift_pitch(original, rate, f_ratio)\n",
    "            temp_dict['psola'] = psola_audio\n",
    "            noise_audio = add_noise(psola_audio, 0.001)\n",
    "            temp_dict['noise'] = noise_audio\n",
    "            key = file.split('.')[0]\n",
    "            audio_dict_NL[key] = temp_dict\n",
    "        elif file.endswith('.txt'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "                    key = key.strip()\n",
    "                    sentence = sentence.strip()\n",
    "                    audio_dict_NL[key]['transcript'] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = audio_dict_NL['fn001601']['original']\n",
    "psola = audio_dict_NL['fn001601']['psola']\n",
    "noise = audio_dict_NL['fn001601']['noise']\n",
    "ipd.display(ipd.HTML('Original'))\n",
    "ipd.display(ipd.Audio(original, rate=rate))\n",
    "\n",
    "ipd.display(ipd.HTML('Anonymized'))\n",
    "ipd.display(ipd.Audio(psola, rate=rate))\n",
    "\n",
    "ipd.display(ipd.HTML('with noise'))\n",
    "ipd.display(ipd.Audio(noise, rate=rate))\n",
    "\n",
    "\n",
    "print(audio_dict_NL['fn001601']['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'fn001601'\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "ipd.display(ipd.HTML('Original'))\n",
    "ipd.display(ipd.Audio(original, rate=rate))\n",
    "transcript = audio_dict_NL[key]['transcript'].lower()\n",
    "    \n",
    "# clean\n",
    "text = transcribe_audio(audio_dict_NL[key]['original'], recognizer, 'small')\n",
    "print(\"clean = \", text)\n",
    "\n",
    "# psola\n",
    "text = transcribe_audio(audio_dict_NL[key]['psola'], recognizer, 'small')\n",
    "print(\"psola = \", text)\n",
    "\n",
    "# noise\n",
    "text = transcribe_audio(audio_dict_NL[key]['noise'], recognizer, 'small')\n",
    "print(\"noise = \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wer = []\n",
    "psola_wer = []\n",
    "noise_wer = []\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "\n",
    "for key in audio_dict.keys():\n",
    "    transcript = audio_dict[key]['transcript'].lower()\n",
    "    \n",
    "    # clean\n",
    "    text = transcribe_audio(audio_dict_NL[key]['original'], recognizer, 'small')\n",
    "    clean_wer.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # psola\n",
    "    text = transcribe_audio(audio_dict_NL[key]['psola'], recognizer, 'small')\n",
    "    psola_wer.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # noise\n",
    "    text = transcribe_audio(audio_dict_NL[key]['noise'], recognizer, 'small')\n",
    "    noise_wer.append(jiwer.wer(text.lower(), transcript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
