{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.fft import fft, ifft\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import speech_recognition\n",
    "import soundfile as sf\n",
    "from io import BytesIO\n",
    "import jiwer\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import soundfile\n",
    "import wave\n",
    "from IPython.display import Audio, Markdown\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Psola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemetation from https://github.com/sannawag/TD-PSOLA/blob/master/td_psola.py\n",
    "def psola(signal, peaks, f_ratio):\n",
    "    \"\"\"\n",
    "    Time-Domain Pitch Synchronous Overlap and Add\n",
    "    :param signal: original time-domain signal\n",
    "    :param peaks: time-domain signal peak indices\n",
    "    :param f_ratio: pitch shift ratio\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    # Interpolate\n",
    "    new_signal = np.zeros(N)\n",
    "    new_peaks_ref = np.linspace(0, len(peaks) - 1, int(len(peaks) * f_ratio))\n",
    "    new_peaks = np.zeros(len(new_peaks_ref)).astype(int)\n",
    "    \n",
    "    for i in range(len(new_peaks)):\n",
    "        weight = new_peaks_ref[i] % 1\n",
    "        left = np.floor(new_peaks_ref[i]).astype(int)\n",
    "        right = np.ceil(new_peaks_ref[i]).astype(int)\n",
    "        new_peaks[i] = int(peaks[left] * (1 - weight) + peaks[right] * weight)\n",
    "\n",
    "    # PSOLA\n",
    "    for j in range(len(new_peaks)):\n",
    "        # find the corresponding old peak index\n",
    "        i = np.argmin(np.abs(peaks - new_peaks[j]))\n",
    "        # get the distances to adjacent peaks\n",
    "        P1 = [new_peaks[j] if j == 0 else new_peaks[j] - new_peaks[j-1],\n",
    "              N - 1 - new_peaks[j] if j == len(new_peaks) - 1 else new_peaks[j+1] - new_peaks[j]]\n",
    "        # edge case truncation\n",
    "        if peaks[i] - P1[0] < 0:\n",
    "            P1[0] = peaks[i]\n",
    "        if peaks[i] + P1[1] > N - 1:\n",
    "            P1[1] = N - 1 - peaks[i]\n",
    "        # linear OLA window\n",
    "        window = list(np.linspace(0, 1, P1[0] + 1)[1:]) + list(np.linspace(1, 0, P1[1] + 1)[1:])\n",
    "        # center window from original signal at the new peak\n",
    "        new_signal[new_peaks[j] - P1[0]: new_peaks[j] + P1[1]] += window * signal[peaks[i] - P1[0]: peaks[i] + P1[1]]\n",
    "    return new_signal\n",
    "\n",
    "def compute_periods_per_sequence(signal, sequence, min_period, max_period):\n",
    "    \"\"\"\n",
    "    Computes periodicity of a time-domain signal using autocorrelation\n",
    "    :param sequence: analysis window length in samples. Computes one periodicity value per window\n",
    "    :param min_period: smallest allowed periodicity\n",
    "    :param max_period: largest allowed periodicity\n",
    "    :return: list of measured periods in windows across the signal\n",
    "    \"\"\"\n",
    "    offset = 0  # current sample offset\n",
    "    periods = []  # period length of each analysis sequence\n",
    "    N = len(signal)\n",
    "    while offset < N:\n",
    "        fourier = fft(signal[offset: offset + sequence])\n",
    "        fourier[0] = 0  # remove DC component\n",
    "        autoc = ifft(fourier * np.conj(fourier)).real\n",
    "        if len(autoc) <= min_period:\n",
    "            autoc_peak = min_period + autoc[-1]\n",
    "        else:    \n",
    "            autoc_peak = min_period + np.argmax(autoc[min_period: max_period])\n",
    "        periods.append(autoc_peak)\n",
    "        offset += sequence\n",
    "    return periods\n",
    "\n",
    "def find_peaks(signal, fs, max_hz=950, min_hz=75, analysis_win_ms=40, max_change=1.005, min_change=0.995):\n",
    "    \"\"\"\n",
    "    Find sample indices of peaks in time-domain signal\n",
    "    :param max_hz: maximum measured fundamental frequency\n",
    "    :param min_hz: minimum measured fundamental frequency\n",
    "    :param analysis_win_ms: window size used for autocorrelation analysis\n",
    "    :param max_change: restrict periodicity to not increase by more than this ratio from the mean\n",
    "    :param min_change: restrict periodicity to not decrease by more than this ratio from the mean\n",
    "    :return: peak indices\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    min_period = fs // max_hz\n",
    "    max_period = fs // min_hz\n",
    "\n",
    "    # compute pitch periodicity\n",
    "    sequence = int(analysis_win_ms / 1000 * fs)  # analysis sequence length in samples\n",
    "\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period)\n",
    "\n",
    "    # simple hack to avoid octave error: assume that the pitch should not vary much, restrict range\n",
    "    mean_period = np.mean(periods)\n",
    "    max_period = int(mean_period * 1.1)\n",
    "    min_period = int(mean_period * 0.9)\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period)\n",
    "\n",
    "    # find the peaks\n",
    "    peaks = [np.argmax(signal[:int(periods[0]*1.1)])]\n",
    "    while True:\n",
    "        prev = peaks[-1]\n",
    "        idx = prev // sequence  # current autocorrelation analysis window\n",
    "        if prev + int(periods[idx] * max_change) >= N:\n",
    "            break\n",
    "        # find maximum near expected location\n",
    "        peaks.append(prev + int(periods[idx] * min_change) +\n",
    "                np.argmax(signal[prev + int(periods[idx] * min_change): prev + int(periods[idx] * max_change)]))\n",
    "    return np.array(peaks)\n",
    "\n",
    "def shift_pitch(signal, fs, f_ratio):\n",
    "    \"\"\"\n",
    "    Calls psola pitch shifting algorithm\n",
    "    :param signal: original signal in the time-domain\n",
    "    :param fs: sample rate\n",
    "    :param f_ratio: ratio by which the frequency will be shifted\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    peaks = find_peaks(signal, fs)\n",
    "    new_signal = psola(signal, peaks, f_ratio)\n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(input_signal, noise_level):\n",
    "    white_noise = np.random.randn(len(input_signal))\n",
    "    mixed_audio = input_signal + noise_level * white_noise[:len(input_signal)]\n",
    "    return mixed_audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file, recognizer, language):\n",
    "    # Language Code for Dutch = \"nl-NL\", for english use \"en-US\"\n",
    "    \n",
    "    # try:\n",
    "    wav_io = BytesIO()\n",
    "    sf.write(wav_io, file, 16000, format='WAV')\n",
    "    wav_io.seek(0)\n",
    "    \n",
    "    audio_file = speech_recognition.AudioFile(wav_io)\n",
    "    with audio_file as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "    \n",
    "    text = recognizer.recognize_whisper(audio_data, language)\n",
    "    wav_io.close()\n",
    "    if text == \"\":\n",
    "        text = \"empty\"\n",
    "    return text  \n",
    "    # except:\n",
    "    #     return \"empty\"\n",
    "    # finally:\n",
    "    #    wav_io.close()\n",
    "      \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n"
     ]
    }
   ],
   "source": [
    "def extract_mfcc(y, n_mfcc=13, rate=16000):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the audio file.\n",
    "    n_mfcc (int): Number of MFCC features to extract.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Extracted MFCC features.\n",
    "    \"\"\"\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=rate, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs.T, axis=0)  # Average across time frames\n",
    "\n",
    "def aggregate_speaker_features(files):\n",
    "    \"\"\"\n",
    "    Aggregate MFCC features for all recordings of a speaker.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths for a single speaker's recordings.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Aggregated feature vector for the speaker.\n",
    "    \"\"\"\n",
    "    features = [extract_mfcc(file) for file in files]\n",
    "    return np.mean(features, axis=0)\n",
    "\n",
    "def get_speaker_files(base_path):\n",
    "    \"\"\"\n",
    "    Get a dictionary of speaker IDs and their corresponding file paths.\n",
    "    \n",
    "    Parameters:\n",
    "    base_path (str): Base directory containing the audio files.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with speaker IDs as keys and lists of file paths as values.\n",
    "    \"\"\"\n",
    "    speaker_files = defaultdict(list)\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.endswith('.wav'):\n",
    "            speaker_id = file.split('-')[0]\n",
    "            speaker_files[speaker_id].append(os.path.join(base_path, file))\n",
    "    return speaker_files\n",
    "\n",
    "def calculate_similarity_matrix(utterances):\n",
    "    \"\"\"\n",
    "    Compute the voice similarity matrix for given utterances.\n",
    "    \n",
    "    Parameters:\n",
    "    utterances (list): List of feature vectors representing each speaker.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Similarity matrix.\n",
    "    \"\"\"\n",
    "    num_speakers = len(utterances)\n",
    "    similarity_matrix = np.zeros((num_speakers, num_speakers))\n",
    "    \n",
    "    for i in range(num_speakers):\n",
    "        for j in range(num_speakers):\n",
    "            similarity_matrix[i, j] = np.dot(utterances[i], utterances[j]) / (np.linalg.norm(utterances[i]) * np.linalg.norm(utterances[j]))\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "def calculate_diagonal_dominance(matrix):\n",
    "    \"\"\"\n",
    "    Calculate the diagonal dominance of a given similarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.ndarray): Similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: Diagonal dominance value.\n",
    "    \"\"\"\n",
    "    N = matrix.shape[0]\n",
    "    diag_avg = np.mean(np.diag(matrix))\n",
    "    off_diag_mask = np.ones(matrix.shape, dtype=bool)\n",
    "    np.fill_diagonal(off_diag_mask, 0)\n",
    "    off_diag_avg = np.mean(matrix[off_diag_mask])\n",
    "    \n",
    "    return abs(diag_avg - off_diag_avg)\n",
    "\n",
    "def calculate_deid(matrix_oo, matrix_op):\n",
    "    \"\"\"\n",
    "    Calculate the DeID metric given the original and original-protected similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix_oo (np.ndarray): Original similarity matrix.\n",
    "    matrix_op (np.ndarray): Original-protected similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: DeID metric.\n",
    "    \"\"\"\n",
    "    D_diag_OO = calculate_diagonal_dominance(matrix_oo)\n",
    "    D_diag_OP = calculate_diagonal_dominance(matrix_op)\n",
    "    \n",
    "    DeID = 1 - (D_diag_OP / D_diag_OO)\n",
    "    return DeID\n",
    "\n",
    "def calculate_gvd(matrix_oo, matrix_pp):\n",
    "    \"\"\"\n",
    "    Calculate the GVD metric given the original and pseudonymised similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix_oo (np.ndarray): Original similarity matrix.\n",
    "    matrix_pp (np.ndarray): Pseudonymised similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: GVD metric.\n",
    "    \"\"\"\n",
    "    D_diag_OO = calculate_diagonal_dominance(matrix_oo)\n",
    "    D_diag_PP = calculate_diagonal_dominance(matrix_pp)\n",
    "    \n",
    "    GVD = 10 * np.log10(D_diag_PP / D_diag_OO)\n",
    "    return GVD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On dev-clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/dev-clean-audio'\n",
    "audio_dict = {}\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        if file.endswith('.wav'):\n",
    "            temp_dict = {}\n",
    "            original, rate = librosa.load(file_path, sr=16000)\n",
    "            temp_dict['original'] = original\n",
    "            f_ratio = 1.3\n",
    "            psola_audio = shift_pitch(original, rate, f_ratio)\n",
    "            temp_dict['psola'] = psola_audio\n",
    "            noise_audio = add_noise(psola_audio, 0.001)\n",
    "            temp_dict['noise'] = noise_audio\n",
    "            key = file.split('.')[0]\n",
    "            audio_dict[key] = temp_dict\n",
    "        elif file.endswith('.txt'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "                    key = key.strip()\n",
    "                    sentence = sentence.strip()\n",
    "                    audio_dict[key]['transcript'] = sentence\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wer = []\n",
    "psola_wer = []\n",
    "noise_wer = []\n",
    "\n",
    "recognizer = speech_recognition.Recognizer()\n",
    "\n",
    "\n",
    "for key in audio_dict.keys():\n",
    "    transcript = audio_dict[key]['transcript'].lower()\n",
    "    \n",
    "    # clean\n",
    "    text = transcribe_audio(audio_dict[key]['original'], recognizer, 'tiny')\n",
    "    clean_wer.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # psola\n",
    "    text = transcribe_audio(audio_dict[key]['psola'], recognizer, 'tiny')\n",
    "    psola_wer.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # noise\n",
    "    text = transcribe_audio(audio_dict[key]['noise'], recognizer, 'tiny')\n",
    "    noise_wer.append(jiwer.wer(text.lower(), transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  0.23365612442399394\n",
      "PSOLA:  0.2508304506804439\n",
      "PSOLA + noise:  0.25760155178128086\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", sum(clean_wer) / len(clean_wer))\n",
    "print(\"PSOLA: \", sum(psola_wer) / len(psola_wer))\n",
    "print(\"PSOLA + noise: \", sum(noise_wer) / len(noise_wer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeID psola: 0.13\n",
      "GVD psola: -0.93\n",
      "DeID noise: 0.18\n",
      "GVD noise: -1.14\n"
     ]
    }
   ],
   "source": [
    "speaker_files = defaultdict(list)\n",
    "speaker_files_psola = defaultdict(list)\n",
    "speaker_files_noise = defaultdict(list)\n",
    "for key, items in audio_dict.items():\n",
    "   speaker_id = key.split('-')[0] \n",
    "   speaker_files[speaker_id].append(items['original'])\n",
    "   speaker_files_psola[speaker_id].append(items['psola'])\n",
    "   speaker_files_noise[speaker_id].append(items['noise'])\n",
    "\n",
    "utterances_original = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files.items()]\n",
    "utterances_psola = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_psola.items()]\n",
    "utterances_noise = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_noise.items()]\n",
    "\n",
    "# Psola\n",
    "matrix_oo_psola = calculate_similarity_matrix(utterances_original)\n",
    "matrix_op_psola = calculate_similarity_matrix(utterances_original + utterances_psola)[len(utterances_original):, :len(utterances_original)]\n",
    "matrix_pp_psola = calculate_similarity_matrix(utterances_psola)\n",
    "\n",
    "# Calculate DeID\n",
    "deid_psola = calculate_deid(matrix_oo_psola, matrix_op_psola)\n",
    "print(f\"DeID psola: {deid_psola:.2f}\")\n",
    "\n",
    "# Calculate GVD\n",
    "gvd_psola = calculate_gvd(matrix_oo_psola, matrix_pp_psola)\n",
    "print(f\"GVD psola: {gvd_psola:.2f}\")\n",
    "\n",
    "\n",
    "# Psola + Noise\n",
    "matrix_oo_noise = calculate_similarity_matrix(utterances_original)\n",
    "matrix_op_noise = calculate_similarity_matrix(utterances_original + utterances_noise)[len(utterances_original):, :len(utterances_original)]\n",
    "matrix_pp_noise = calculate_similarity_matrix(utterances_noise)\n",
    "\n",
    "# Calculate DeID\n",
    "deid_noise = calculate_deid(matrix_oo_noise, matrix_op_noise)\n",
    "print(f\"DeID noise: {deid_noise:.2f}\")\n",
    "\n",
    "# Calculate GVD\n",
    "gvd_noise = calculate_gvd(matrix_oo_noise, matrix_pp_noise)\n",
    "print(f\"GVD noise: {gvd_noise:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On dutch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/nl'\n",
    "audio_dict_NL = {}\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        if file.endswith('.wav'):\n",
    "            temp_dict = {}\n",
    "            original, rate = librosa.load(file_path, sr=16000)\n",
    "            temp_dict['original'] = original\n",
    "            f_ratio = 1.3\n",
    "            psola_audio = shift_pitch(original, rate, f_ratio)\n",
    "            temp_dict['psola'] = psola_audio\n",
    "            noise_audio = add_noise(psola_audio, 0.001)\n",
    "            temp_dict['noise'] = noise_audio\n",
    "            key = file.split('.')[0]\n",
    "            audio_dict_NL[key] = temp_dict\n",
    "        elif file.endswith('.txt'):\n",
    "            with open(file_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "                    key = key.strip()\n",
    "                    sentence = sentence.strip()\n",
    "                    audio_dict_NL[key]['transcript'] = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wer_NL = []\n",
    "psola_wer_NL = []\n",
    "noise_wer_NL = []\n",
    "\n",
    "recognizer = speech_recognition.Recognizer()\n",
    "\n",
    "\n",
    "for key in audio_dict_NL.keys():\n",
    "    transcript = audio_dict_NL[key]['transcript'].lower()\n",
    "    \n",
    "    # clean\n",
    "    text = transcribe_audio(audio_dict_NL[key]['original'], recognizer, 'tiny')\n",
    "    clean_wer_NL.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # psola\n",
    "    text = transcribe_audio(audio_dict_NL[key]['psola'], recognizer, 'tiny')\n",
    "    psola_wer_NL.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # noise\n",
    "    text = transcribe_audio(audio_dict_NL[key]['noise'], recognizer, 'tiny')\n",
    "    noise_wer_NL.append(jiwer.wer(text.lower(), transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  0.49291687579217325\n",
      "PSOLA:  0.5338737449221851\n",
      "PSOLA + noise:  0.5431410591421738\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", sum(clean_wer_NL) / len(clean_wer_NL))\n",
    "print(\"PSOLA: \", sum(psola_wer_NL) / len(psola_wer_NL))\n",
    "print(\"PSOLA + noise: \", sum(noise_wer_NL) / len(noise_wer_NL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeID psola: 0.11\n",
      "GVD psola: -0.84\n",
      "DeID noise: 0.13\n",
      "GVD noise: -0.67\n"
     ]
    }
   ],
   "source": [
    "speaker_files_NL = defaultdict(list)\n",
    "speaker_files_psola_NL = defaultdict(list)\n",
    "speaker_files_noise_NL = defaultdict(list)\n",
    "\n",
    "with open('files_for_harm/spk2utt.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.split(' ')\n",
    "        audios_clean = []\n",
    "        audios_psola = []\n",
    "        audios_noise = []\n",
    "        for i in parts[1:]:\n",
    "            i = i.strip()\n",
    "            audios_clean.append(audio_dict_NL[i]['original'])\n",
    "            audios_psola.append(audio_dict_NL[i]['psola'])\n",
    "            audios_noise.append(audio_dict_NL[i]['noise'])\n",
    "        speaker_files_NL[parts[0]] = audios_clean\n",
    "        speaker_files_psola_NL[parts[0]] = audios_psola\n",
    "        speaker_files_noise_NL[parts[0]] = audios_noise\n",
    "        \n",
    "utterances_original_NL = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_NL.items()]\n",
    "utterances_psola_NL = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_psola_NL.items()]\n",
    "utterances_noise_NL = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_noise_NL.items()]\n",
    "\n",
    "# Psola\n",
    "matrix_oo_psola_NL = calculate_similarity_matrix(utterances_original_NL)\n",
    "matrix_op_psola_NL = calculate_similarity_matrix(utterances_original_NL + utterances_psola_NL)[len(utterances_original_NL):, :len(utterances_original_NL)]\n",
    "matrix_pp_psola_NL = calculate_similarity_matrix(utterances_psola_NL)\n",
    "\n",
    "# Calculate DeID\n",
    "deid_psola_NL = calculate_deid(matrix_oo_psola_NL, matrix_op_psola_NL)\n",
    "print(f\"DeID psola: {deid_psola_NL:.2f}\")\n",
    "\n",
    "# Calculate GVD\n",
    "gvd_psola_NL = calculate_gvd(matrix_oo_psola_NL, matrix_pp_psola_NL)\n",
    "print(f\"GVD psola: {gvd_psola_NL:.2f}\")\n",
    "\n",
    "\n",
    "# Psola + Noise\n",
    "matrix_oo_noise_NL = calculate_similarity_matrix(utterances_original_NL)\n",
    "matrix_op_noise_NL = calculate_similarity_matrix(utterances_original_NL + utterances_noise_NL)[len(utterances_original_NL):, :len(utterances_original_NL)]\n",
    "matrix_pp_noise_NL = calculate_similarity_matrix(utterances_noise_NL)\n",
    "\n",
    "# Calculate DeID\n",
    "deid_noise_NL = calculate_deid(matrix_oo_noise_NL, matrix_op_noise_NL)\n",
    "print(f\"DeID noise: {deid_noise_NL:.2f}\")\n",
    "\n",
    "# Calculate GVD\n",
    "gvd_noise_NL = calculate_gvd(matrix_oo_noise_NL, matrix_pp_noise_NL)\n",
    "print(f\"GVD noise: {gvd_noise_NL:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on VCTK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/wav_vctk'\n",
    "audio_dict_VCTK = {}\n",
    "for root, dirs, files in os.walk(data_folder):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_path = file_path.replace('\\\\', '/')\n",
    "        if file.endswith('.wav'):\n",
    "            temp_dict = {}\n",
    "            original, rate = librosa.load(file_path, sr=16000)\n",
    "            temp_dict['original'] = original\n",
    "            f_ratio = 1.3\n",
    "            psola_audio = shift_pitch(original, rate, f_ratio)\n",
    "            temp_dict['psola'] = psola_audio\n",
    "            noise_audio = add_noise(psola_audio, 0.001)\n",
    "            temp_dict['noise'] = noise_audio\n",
    "            parts = file.split('_')\n",
    "            key = '_'.join(parts[:2])\n",
    "            audio_dict_VCTK[key] = temp_dict\n",
    "\n",
    "transcripts_path = \"data/wav_vctk/transcripts.txt\"\n",
    "with open(transcripts_path, 'r') as f:\n",
    "    for line in f:\n",
    "        key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "        key = key.strip()\n",
    "        sentence = sentence.strip()\n",
    "        audio_dict_VCTK[key]['transcript'] = sentence\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wer_VCTK = []\n",
    "psola_wer_VCTK = []\n",
    "noise_wer_VCTK = []\n",
    "\n",
    "recognizer = speech_recognition.Recognizer()\n",
    "\n",
    "\n",
    "for key in audio_dict_VCTK.keys():\n",
    "    transcript = audio_dict_VCTK[key]['transcript'].lower()\n",
    "    \n",
    "    # clean\n",
    "    text = transcribe_audio(audio_dict_VCTK[key]['original'], recognizer, 'tiny')\n",
    "    if text != \"empty\":\n",
    "        clean_wer_VCTK.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # psola\n",
    "    \n",
    "    text = transcribe_audio(audio_dict_VCTK[key]['psola'], recognizer, 'tiny')\n",
    "    \n",
    "    if text != \"empty\":\n",
    "        psola_wer_VCTK.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # noise\n",
    "    text = transcribe_audio(audio_dict_VCTK[key]['noise'], recognizer, 'tiny')\n",
    "    \n",
    "    if text != \"empty\":\n",
    "        noise_wer_VCTK.append(jiwer.wer(text.lower(), transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  0.14842702731034715\n",
      "PSOLA:  0.17863867799899005\n",
      "PSOLA + noise:  0.18156435380337635\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: \", sum(clean_wer_VCTK) / len(clean_wer_VCTK))\n",
    "print(\"PSOLA: \", sum(psola_wer_VCTK) / len(psola_wer_VCTK))\n",
    "print(\"PSOLA + noise: \", sum(noise_wer_VCTK) / len(noise_wer_VCTK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeID psola: 0.21\n",
      "GVD psola: -1.31\n",
      "DeID noise: 0.25\n",
      "GVD noise: -1.15\n"
     ]
    }
   ],
   "source": [
    "speaker_files_VCTK = defaultdict(list)\n",
    "speaker_files_psola_VCTK = defaultdict(list)\n",
    "speaker_files_noise_VCTK = defaultdict(list)\n",
    "for key, items in audio_dict_VCTK.items():\n",
    "   speaker_id = key.split('_')[0] \n",
    "   speaker_files_VCTK[speaker_id].append(items['original'])\n",
    "   speaker_files_psola_VCTK[speaker_id].append(items['psola'])\n",
    "   speaker_files_noise_VCTK[speaker_id].append(items['noise'])\n",
    "\n",
    "utterances_original_VCTK = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_VCTK.items()]\n",
    "utterances_psola_VCTK = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_psola_VCTK.items()]\n",
    "utterances_noise_VCTK = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_noise_VCTK.items()]\n",
    "\n",
    "# Psola\n",
    "matrix_oo_psola_VCTK = calculate_similarity_matrix(utterances_original_VCTK)\n",
    "matrix_op_psola_VCTK = calculate_similarity_matrix(utterances_original_VCTK + utterances_psola_VCTK)[len(utterances_original_VCTK):, :len(utterances_original_VCTK)]\n",
    "matrix_pp_psola_VCTK = calculate_similarity_matrix(utterances_psola_VCTK)\n",
    "\n",
    "# Calculate DeID\n",
    "deid_psola_VCTK = calculate_deid(matrix_oo_psola_VCTK, matrix_op_psola_VCTK)\n",
    "print(f\"DeID psola: {deid_psola_VCTK:.2f}\")\n",
    "\n",
    "# Calculate GVD\n",
    "gvd_psola_VCTK = calculate_gvd(matrix_oo_psola_VCTK, matrix_pp_psola_VCTK)\n",
    "print(f\"GVD psola: {gvd_psola_VCTK:.2f}\")\n",
    "\n",
    "\n",
    "# Psola + Noise\n",
    "matrix_oo_noise_VCTK = calculate_similarity_matrix(utterances_original_VCTK)\n",
    "matrix_op_noise_VCTK = calculate_similarity_matrix(utterances_original_VCTK + utterances_noise_VCTK)[len(utterances_original_VCTK):, :len(utterances_original_VCTK)]\n",
    "matrix_pp_noise_VCTK = calculate_similarity_matrix(utterances_noise_VCTK)\n",
    "\n",
    "# Calculate DeID\n",
    "deid_noise_VCTK = calculate_deid(matrix_oo_noise_VCTK, matrix_op_noise_VCTK)\n",
    "print(f\"DeID noise: {deid_noise_VCTK:.2f}\")\n",
    "\n",
    "# Calculate GVD\n",
    "gvd_noise_VCTK = calculate_gvd(matrix_oo_noise_VCTK, matrix_pp_noise_VCTK)\n",
    "print(f\"GVD noise: {gvd_noise_VCTK:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
