{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import soundfile\n",
    "import numpy as np\n",
    "import wave\n",
    "import os\n",
    "from numpy.fft import fft, ifft\n",
    "from IPython.display import Audio, Markdown\n",
    "from collections import defaultdict\n",
    "import speech_recognition\n",
    "from io import BytesIO\n",
    "import jiwer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_path, n_mfcc=13):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the audio file.\n",
    "    n_mfcc (int): Number of MFCC features to extract.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Extracted MFCC features.\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs.T, axis=0)  # Average across time frames\n",
    "\n",
    "def aggregate_speaker_features(file_paths):\n",
    "    \"\"\"\n",
    "    Aggregate MFCC features for all recordings of a speaker.\n",
    "    \n",
    "    Parameters:\n",
    "    file_paths (list): List of file paths for a single speaker's recordings.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Aggregated feature vector for the speaker.\n",
    "    \"\"\"\n",
    "    features = [extract_mfcc(file) for file in file_paths]\n",
    "    return np.mean(features, axis=0)\n",
    "\n",
    "def get_speaker_files(base_path, split_token='-'):\n",
    "    \"\"\"\n",
    "    Get a dictionary of speaker IDs and their corresponding file paths.\n",
    "    \n",
    "    Parameters:\n",
    "    base_path (str): Base directory containing the audio files.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with speaker IDs as keys and lists of file paths as values.\n",
    "    \"\"\"\n",
    "    speaker_files = defaultdict(list)\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.endswith('.wav'):\n",
    "            speaker_id = file.split(split_token)[0]\n",
    "            speaker_files[speaker_id].append(os.path.join(base_path, file))\n",
    "    return speaker_files\n",
    "\n",
    "def calculate_similarity_matrix(utterances):\n",
    "    \"\"\"\n",
    "    Compute the voice similarity matrix for given utterances.\n",
    "    \n",
    "    Parameters:\n",
    "    utterances (list): List of feature vectors representing each speaker.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: Similarity matrix.\n",
    "    \"\"\"\n",
    "    num_speakers = len(utterances)\n",
    "    similarity_matrix = np.zeros((num_speakers, num_speakers))\n",
    "    \n",
    "    for i in range(num_speakers):\n",
    "        for j in range(num_speakers):\n",
    "            similarity_matrix[i, j] = np.dot(utterances[i], utterances[j]) / (np.linalg.norm(utterances[i]) * np.linalg.norm(utterances[j]))\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "def calculate_diagonal_dominance(matrix):\n",
    "    \"\"\"\n",
    "    Calculate the diagonal dominance of a given similarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.ndarray): Similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: Diagonal dominance value.\n",
    "    \"\"\"\n",
    "    N = matrix.shape[0]\n",
    "    diag_avg = np.mean(np.diag(matrix))\n",
    "    off_diag_mask = np.ones(matrix.shape, dtype=bool)\n",
    "    np.fill_diagonal(off_diag_mask, 0)\n",
    "    off_diag_avg = np.mean(matrix[off_diag_mask])\n",
    "    \n",
    "    return abs(diag_avg - off_diag_avg)\n",
    "\n",
    "def calculate_deid(matrix_oo, matrix_op):\n",
    "    \"\"\"\n",
    "    Calculate the DeID metric given the original and original-protected similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix_oo (np.ndarray): Original similarity matrix.\n",
    "    matrix_op (np.ndarray): Original-protected similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: DeID metric.\n",
    "    \"\"\"\n",
    "    D_diag_OO = calculate_diagonal_dominance(matrix_oo)\n",
    "    D_diag_OP = calculate_diagonal_dominance(matrix_op)\n",
    "    \n",
    "    DeID = 1 - (D_diag_OP / D_diag_OO)\n",
    "    return DeID\n",
    "\n",
    "def calculate_gvd(matrix_oo, matrix_pp):\n",
    "    \"\"\"\n",
    "    Calculate the GVD metric given the original and pseudonymised similarity matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix_oo (np.ndarray): Original similarity matrix.\n",
    "    matrix_pp (np.ndarray): Pseudonymised similarity matrix.\n",
    "    \n",
    "    Returns:\n",
    "    float: GVD metric.\n",
    "    \"\"\"\n",
    "    D_diag_OO = calculate_diagonal_dominance(matrix_oo)\n",
    "    D_diag_PP = calculate_diagonal_dominance(matrix_pp)\n",
    "    \n",
    "    GVD = 10 * np.log10(D_diag_PP / D_diag_OO)\n",
    "    return GVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_files(base_path, split_token='.'):\n",
    "    \"\"\"\n",
    "    Get a dictionary of speaker IDs and their corresponding file paths.\n",
    "    \n",
    "    Parameters:\n",
    "    base_path (str): Base directory containing the audio files.\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with audio IDs as keys and file path as values.\n",
    "    \"\"\"\n",
    "    wav_files = {}\n",
    "    for file in os.listdir(base_path):\n",
    "        if file.endswith('.wav'):\n",
    "            audio_id = file.split(split_token)[0]\n",
    "            wav_files[audio_id] = os.path.join(base_path, file)\n",
    "    return wav_files\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_audio(file_path, recognizer, model):\n",
    "    # print(file_path)\n",
    "    \n",
    "    audio_file = speech_recognition.AudioFile(file_path)\n",
    "    with audio_file as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "    \n",
    "    text = recognizer.recognize_whisper(audio_data, model)\n",
    "    if text == \"\":\n",
    "        text = \"empty\"\n",
    "    return text  \n",
    "\n",
    "def transcribe_audio2(file_path, recognizer, model):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    # print(file_path)\n",
    "\n",
    "    wav_io = BytesIO()\n",
    "    sf.write(wav_io, y, 16000, format='WAV')\n",
    "    wav_io.seek(0)\n",
    "\n",
    "    audio_file = speech_recognition.AudioFile(wav_io)\n",
    "    with audio_file as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "\n",
    "    text = recognizer.recognize_whisper(audio_data, 'tiny')\n",
    "    wav_io.close()\n",
    "    if text == \"\":\n",
    "        text = \"empty\"\n",
    "    return text  \n",
    "\n",
    "# Gender mapping\n",
    "spk2gender = {\n",
    "    '1272': 'm', '1462': 'f', '1673': 'f', '174': 'm', '1919': 'f', '1988': 'f', \n",
    "    '1993': 'f', '2035': 'f', '2078': 'm', '2086': 'm', '2277': 'f', '2412': 'f', \n",
    "    '2428': 'm', '251': 'm', '2803': 'm', '2902': 'm', '3000': 'm', '3081': 'f', \n",
    "    '3170': 'm', '3536': 'f', '3576': 'f', '3752': 'm', '3853': 'f', '422': 'm', \n",
    "    '5338': 'f', '5536': 'm', '5694': 'm', '5895': 'f', '6241': 'm', '6295': 'm', \n",
    "    '6313': 'f', '6319': 'f', '6345': 'f', '652': 'm', '777': 'm', '7850': 'f', \n",
    "    '7976': 'm', '8297': 'm', '84': 'f', '8842': 'f'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libri-dev\n",
    "\n",
    "\n",
    "voice privacy challange - asrbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male DeID: 0.86, Male GVD: -9.48\n",
      "Female DeID: 0.95, Female GVD: -11.92\n"
     ]
    }
   ],
   "source": [
    "# Get speaker files and aggregate features\n",
    "base_dir = 'data/dev-clean-audio'\n",
    "speaker_files = get_speaker_files(base_dir)\n",
    "\n",
    "# Separating male and female speakers\n",
    "male_speakers = {spk: paths for spk, paths in speaker_files.items() if spk2gender[spk] == 'm'}\n",
    "female_speakers = {spk: paths for spk, paths in speaker_files.items() if spk2gender[spk] == 'f'}\n",
    "\n",
    "utterances_male = [aggregate_speaker_features(paths) for spk, paths in male_speakers.items()]\n",
    "utterances_female = [aggregate_speaker_features(paths) for spk, paths in female_speakers.items()]\n",
    "\n",
    "# Calculating similarity matrices for male and female\n",
    "matrix_oo_male = calculate_similarity_matrix(utterances_male)\n",
    "matrix_oo_female = calculate_similarity_matrix(utterances_female)\n",
    "\n",
    "# Get speaker files and aggregate features for pseudonymised data\n",
    "base_dir_pseudo = 'data/anonymized/vpc/libri_dev/asrbn_libri_dev'\n",
    "speaker_files_pseudo = get_speaker_files(base_dir_pseudo)\n",
    "utterances_pseudonymised = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_pseudo.items()]\n",
    "\n",
    "# Separating male and female speakers\n",
    "pseudo_male_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'm'}\n",
    "pseudo_female_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'f'}\n",
    "\n",
    "utterances_pseudo_male = [aggregate_speaker_features(paths) for spk, paths in pseudo_male_speakers.items()]\n",
    "utterances_pseudo_female = [aggregate_speaker_features(paths) for spk, paths in pseudo_female_speakers.items()]\n",
    "\n",
    "# Male DeID and GVD\n",
    "matrix_op_male = calculate_similarity_matrix(utterances_male + utterances_pseudo_male)[len(utterances_male):, :len(utterances_male)]\n",
    "matrix_pp_male = calculate_similarity_matrix(utterances_pseudo_male)\n",
    "\n",
    "deid_male = calculate_deid(matrix_oo_male, matrix_op_male)\n",
    "gvd_male = calculate_gvd(matrix_oo_male, matrix_pp_male)\n",
    "\n",
    "# Female DeID and GVD\n",
    "matrix_op_female = calculate_similarity_matrix(utterances_female + utterances_pseudo_female)[len(utterances_female):, :len(utterances_female)]\n",
    "matrix_pp_female = calculate_similarity_matrix(utterances_pseudo_female)\n",
    "\n",
    "deid_female = calculate_deid(matrix_oo_female, matrix_op_female)\n",
    "gvd_female = calculate_gvd(matrix_oo_female, matrix_pp_female)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Male DeID: {deid_male:.2f}, Male GVD: {gvd_male:.2f}\")\n",
    "print(f\"Female DeID: {deid_female:.2f}, Female GVD: {gvd_female:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mcadams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male DeID: 0.58, Male GVD: 4.22\n",
      "Female DeID: 0.56, Female GVD: 3.42\n"
     ]
    }
   ],
   "source": [
    "# Get speaker files and aggregate features for pseudonymised data\n",
    "base_dir_pseudo = 'data/anonymized/vpc/libri_dev/mcadams_libri_dev'\n",
    "speaker_files_pseudo = get_speaker_files(base_dir_pseudo)\n",
    "utterances_pseudonymised = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_pseudo.items()]\n",
    "\n",
    "# Separating male and female speakers\n",
    "pseudo_male_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'm'}\n",
    "pseudo_female_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'f'}\n",
    "\n",
    "utterances_pseudo_male = [aggregate_speaker_features(paths) for spk, paths in pseudo_male_speakers.items()]\n",
    "utterances_pseudo_female = [aggregate_speaker_features(paths) for spk, paths in pseudo_female_speakers.items()]\n",
    "\n",
    "# Male DeID and GVD\n",
    "matrix_op_male = calculate_similarity_matrix(utterances_male + utterances_pseudo_male)[len(utterances_male):, :len(utterances_male)]\n",
    "matrix_pp_male = calculate_similarity_matrix(utterances_pseudo_male)\n",
    "\n",
    "deid_male = calculate_deid(matrix_oo_male, matrix_op_male)\n",
    "gvd_male = calculate_gvd(matrix_oo_male, matrix_pp_male)\n",
    "\n",
    "# Female DeID and GVD\n",
    "matrix_op_female = calculate_similarity_matrix(utterances_female + utterances_pseudo_female)[len(utterances_female):, :len(utterances_female)]\n",
    "matrix_pp_female = calculate_similarity_matrix(utterances_pseudo_female)\n",
    "\n",
    "deid_female = calculate_deid(matrix_oo_female, matrix_op_female)\n",
    "gvd_female = calculate_gvd(matrix_oo_female, matrix_pp_female)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Male DeID: {deid_male:.2f}, Male GVD: {gvd_male:.2f}\")\n",
    "print(f\"Female DeID: {deid_female:.2f}, Female GVD: {gvd_female:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male DeID: 0.89, Male GVD: -10.74\n",
      "Female DeID: 0.97, Female GVD: -11.16\n"
     ]
    }
   ],
   "source": [
    "# Get speaker files and aggregate features for pseudonymised data\n",
    "base_dir_pseudo = 'data/anonymized/vpc/libri_dev/nac_libri_dev'\n",
    "speaker_files_pseudo = get_speaker_files(base_dir_pseudo)\n",
    "utterances_pseudonymised = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_pseudo.items()]\n",
    "\n",
    "# Separating male and female speakers\n",
    "pseudo_male_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'm'}\n",
    "pseudo_female_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'f'}\n",
    "\n",
    "utterances_pseudo_male = [aggregate_speaker_features(paths) for spk, paths in pseudo_male_speakers.items()]\n",
    "utterances_pseudo_female = [aggregate_speaker_features(paths) for spk, paths in pseudo_female_speakers.items()]\n",
    "\n",
    "# Male DeID and GVD\n",
    "matrix_op_male = calculate_similarity_matrix(utterances_male + utterances_pseudo_male)[len(utterances_male):, :len(utterances_male)]\n",
    "matrix_pp_male = calculate_similarity_matrix(utterances_pseudo_male)\n",
    "\n",
    "deid_male = calculate_deid(matrix_oo_male, matrix_op_male)\n",
    "gvd_male = calculate_gvd(matrix_oo_male, matrix_pp_male)\n",
    "\n",
    "# Female DeID and GVD\n",
    "matrix_op_female = calculate_similarity_matrix(utterances_female + utterances_pseudo_female)[len(utterances_female):, :len(utterances_female)]\n",
    "matrix_pp_female = calculate_similarity_matrix(utterances_pseudo_female)\n",
    "\n",
    "deid_female = calculate_deid(matrix_oo_female, matrix_op_female)\n",
    "gvd_female = calculate_gvd(matrix_oo_female, matrix_pp_female)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Male DeID: {deid_male:.2f}, Male GVD: {gvd_male:.2f}\")\n",
    "print(f\"Female DeID: {deid_female:.2f}, Female GVD: {gvd_female:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSL_SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male DeID: 0.95, Male GVD: -3.85\n",
      "Female DeID: 0.91, Female GVD: -6.20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir_pseudo = 'data/anonymized/ssl_sas/ssl_sas_libri_dev'\n",
    "speaker_files_pseudo = get_speaker_files(base_dir_pseudo)\n",
    "utterances_pseudonymised = [aggregate_speaker_features(paths) for speaker_id, paths in speaker_files_pseudo.items()]\n",
    "\n",
    "# Separating male and female speakers\n",
    "pseudo_male_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'm'}\n",
    "pseudo_female_speakers = {spk: paths for spk, paths in speaker_files_pseudo.items() if spk2gender[spk] == 'f'}\n",
    "\n",
    "utterances_pseudo_male = [aggregate_speaker_features(paths) for spk, paths in pseudo_male_speakers.items()]\n",
    "utterances_pseudo_female = [aggregate_speaker_features(paths) for spk, paths in pseudo_female_speakers.items()]\n",
    "\n",
    "# Male DeID and GVD\n",
    "matrix_op_male = calculate_similarity_matrix(utterances_male + utterances_pseudo_male)[len(utterances_male):, :len(utterances_male)]\n",
    "matrix_pp_male = calculate_similarity_matrix(utterances_pseudo_male)\n",
    "\n",
    "deid_male = calculate_deid(matrix_oo_male, matrix_op_male)\n",
    "gvd_male = calculate_gvd(matrix_oo_male, matrix_pp_male)\n",
    "\n",
    "# Female DeID and GVD\n",
    "matrix_op_female = calculate_similarity_matrix(utterances_female + utterances_pseudo_female)[len(utterances_female):, :len(utterances_female)]\n",
    "matrix_pp_female = calculate_similarity_matrix(utterances_pseudo_female)\n",
    "\n",
    "deid_female = calculate_deid(matrix_oo_female, matrix_op_female)\n",
    "gvd_female = calculate_gvd(matrix_oo_female, matrix_pp_female)\n",
    "\n",
    "# Displaying results\n",
    "print(f\"Male DeID: {deid_male:.2f}, Male GVD: {gvd_male:.2f}\")\n",
    "print(f\"Female DeID: {deid_female:.2f}, Female GVD: {gvd_female:.2f}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2321/2321 [42:19<00:00,  1.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean WER Male: 0.24064532517504425\n",
      "Clean WER Female: 0.2263667482594354\n",
      "ASRBN WER Male: 0.27644587722404496\n",
      "ASRBN WER Female: 0.2635742301886673\n",
      "McAdams WER Male: 0.6672536801121404\n",
      "McAdams WER Female: 0.5171989811663409\n",
      "NAC WER Male: 0.3297330855097981\n",
      "NAC WER Female: 0.3079999092872537\n",
      "SSL-SAS WER Male: 0.2471018092813415\n",
      "SSL-SAS WER Female: 0.2363985067938919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load transcripts\n",
    "transcripts_path = \"data/dev-clean-audio/transcript.txt\"\n",
    "\n",
    "def transcribe_audio2(file_path, recognizer, model):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    # print(file_path)\n",
    "\n",
    "    wav_io = BytesIO()\n",
    "    sf.write(wav_io, y, 16000, format='WAV')\n",
    "    wav_io.seek(0)\n",
    "\n",
    "    audio_file = speech_recognition.AudioFile(wav_io)\n",
    "    with audio_file as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "\n",
    "    text = recognizer.recognize_whisper(audio_data, 'tiny')\n",
    "    wav_io.close()\n",
    "    if text == \"\":\n",
    "        text = \"empty\"\n",
    "    return text  \n",
    "\n",
    "transcrips_dict = {}\n",
    "with open(transcripts_path, 'r') as f:\n",
    "    for line in f:\n",
    "        key, sentence = line.split(' ', 1)  # Split on the first space\n",
    "        key = key.strip()\n",
    "        sentence = sentence.strip()\n",
    "        transcrips_dict[key] = sentence\n",
    "\n",
    "# Load paths for different audio sets\n",
    "clean_paths = get_wav_files('data/dev-clean-audio')\n",
    "asrbn_paths = get_wav_files('data/anonymized/vpc/libri_dev/asrbn_libri_dev')\n",
    "mcadams_paths = get_wav_files('data/anonymized/vpc/libri_dev/mcadams_libri_dev')\n",
    "nac_paths = get_wav_files('data/anonymized/vpc/libri_dev/nac_libri_dev')\n",
    "sslsas_paths = get_wav_files('data/anonymized/ssl_sas/ssl_sas_libri_dev', '_')\n",
    "\n",
    "# Initialize lists to store WER values for male and female speakers\n",
    "clean_wer_male = []\n",
    "clean_wer_female = []\n",
    "asrbn_wer_male = []\n",
    "asrbn_wer_female = []\n",
    "mcadams_wer_male = []\n",
    "mcadams_wer_female = []\n",
    "nac_wer_male = []\n",
    "nac_wer_female = []\n",
    "sslsas_wer_male = []\n",
    "sslsas_wer_female = []\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = speech_recognition.Recognizer()\n",
    "\n",
    "# Calculate WER separately for male and female speakers\n",
    "for key, t in tqdm(transcrips_dict.items()):\n",
    "    transcript = t.lower()\n",
    "    speaker_id = key.split('-')[0]\n",
    "    gender = spk2gender[speaker_id]\n",
    "    \n",
    "    # clean\n",
    "    if key in clean_paths:\n",
    "        text = transcribe_audio2(clean_paths[key], recognizer, 'tiny')\n",
    "        if text != \"empty\":\n",
    "            if gender == 'm':\n",
    "                clean_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "            else:\n",
    "                clean_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # asrbn\n",
    "    if key in asrbn_paths:\n",
    "        text = transcribe_audio2(asrbn_paths[key], recognizer, 'tiny')\n",
    "        if text != \"empty\":\n",
    "            if gender == 'm':\n",
    "                asrbn_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "            else:\n",
    "                asrbn_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # mcadams\n",
    "    if key in mcadams_paths:\n",
    "        text = transcribe_audio2(mcadams_paths[key], recognizer, 'tiny')\n",
    "        if text != \"empty\":\n",
    "            if gender == 'm':\n",
    "                mcadams_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "            else:\n",
    "                mcadams_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # nac\n",
    "    if key in nac_paths:\n",
    "        text = transcribe_audio2(nac_paths[key], recognizer, 'tiny')\n",
    "        if text != \"empty\":\n",
    "            if gender == 'm':\n",
    "                nac_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "            else:\n",
    "                nac_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "    \n",
    "    # sslsas\n",
    "    if key in sslsas_paths:\n",
    "        text = transcribe_audio2(sslsas_paths[key], recognizer, 'tiny')\n",
    "        if text != \"empty\":\n",
    "            if gender == 'm':\n",
    "                sslsas_wer_male.append(jiwer.wer(text.lower(), transcript))\n",
    "            else:\n",
    "                sslsas_wer_female.append(jiwer.wer(text.lower(), transcript))\n",
    "\n",
    "# Calculate average WER for male and female speakers\n",
    "clean_wer_male_avg = sum(clean_wer_male) / len(clean_wer_male) if clean_wer_male else float('nan')\n",
    "clean_wer_female_avg = sum(clean_wer_female) / len(clean_wer_female) if clean_wer_female else float('nan')\n",
    "\n",
    "asrbn_wer_male_avg = sum(asrbn_wer_male) / len(asrbn_wer_male) if asrbn_wer_male else float('nan')\n",
    "asrbn_wer_female_avg = sum(asrbn_wer_female) / len(asrbn_wer_female) if asrbn_wer_female else float('nan')\n",
    "\n",
    "mcadams_wer_male_avg = sum(mcadams_wer_male) / len(mcadams_wer_male) if mcadams_wer_male else float('nan')\n",
    "mcadams_wer_female_avg = sum(mcadams_wer_female) / len(mcadams_wer_female) if mcadams_wer_female else float('nan')\n",
    "\n",
    "nac_wer_male_avg = sum(nac_wer_male) / len(nac_wer_male) if nac_wer_male else float('nan')\n",
    "nac_wer_female_avg = sum(nac_wer_female) / len(nac_wer_female) if nac_wer_female else float('nan')\n",
    "\n",
    "sslsas_wer_male_avg = sum(sslsas_wer_male) / len(sslsas_wer_male) if sslsas_wer_male else float('nan')\n",
    "sslsas_wer_female_avg = sum(sslsas_wer_female) / len(sslsas_wer_female) if sslsas_wer_female else float('nan')\n",
    "\n",
    "# Display results\n",
    "print(f\"Clean WER Male: {clean_wer_male_avg}\")\n",
    "print(f\"Clean WER Female: {clean_wer_female_avg}\")\n",
    "print(f\"ASRBN WER Male: {asrbn_wer_male_avg}\")\n",
    "print(f\"ASRBN WER Female: {asrbn_wer_female_avg}\")\n",
    "print(f\"McAdams WER Male: {mcadams_wer_male_avg}\")\n",
    "print(f\"McAdams WER Female: {mcadams_wer_female_avg}\")\n",
    "print(f\"NAC WER Male: {nac_wer_male_avg}\")\n",
    "print(f\"NAC WER Female: {nac_wer_female_avg}\")\n",
    "print(f\"SSL-SAS WER Male: {sslsas_wer_male_avg}\")\n",
    "print(f\"SSL-SAS WER Female: {sslsas_wer_female_avg}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
